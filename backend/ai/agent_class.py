# agent_class.py
import os
import json
import random
import logging
import google.generativeai as genai
from dotenv import load_dotenv
from livekit.agents import Agent
from livekit.agents.llm import function_tool
from livekit.rtc import Room, DataPacket
from analyst_agent import generate_analysis_report

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()

# --- 1. CONFIGURAÇÃO DA IA E PROMPTS ---
try:
    api_key = os.environ.get("GOOGLE_API_KEY") or os.environ.get("GEMINI_API_KEY")
    if not api_key:
        raise KeyError
    genai.configure(api_key=api_key)
except KeyError:
    print("ERRO: GOOGLE_API_KEY ou GEMINI_API_KEY não encontrada no .env")
    exit()

MODEL = genai.GenerativeModel('gemini-1.5-flash')

SOLUTION_FEEDBACK_PROMPT = """
You are a Senior Software Engineer conducting a code review. Your task is to provide constructive feedback on a candidate's solution, using an existing analysis report as a baseline.
**INTERVIEWER'S ANALYSIS REPORT (Your baseline for the optimal solution):**
---
{analysis_report}
---
**CANDIDATE'S SOLUTION (Transcribed from their explanation):**
{user_solution}
**YOUR TASK:**
Analyze the candidate's solution by comparing it with the optimal approach in the report. Generate a final report in Markdown with the following sections: 1. General Feedback, 2. Correctness and Logic, 3. Efficiency (Complexity), 4. Code Quality, 5. Areas for Improvement.
Be professional, encouraging, and technical.
"""

SYSTEM_PROMPT_INTERVIEWER = """
You are an expert interviewer named Ada. You are professional and friendly. Your entire process is a strict, repeating cycle. You MUST follow these steps precisely.
**Interview Flow:**
1. **Greeting:** Start the conversation *only once* with a friendly greeting, introduce yourself, and ask ONE behavioral question.
2. **First Technical Question:** After the candidate answers the behavioral question, you MUST immediately call your `prepare_technical_question` tool.
3. **Conduct Technical Interview:** Use the report from the tool to interview the candidate about this specific problem.
4. **Listen and Conclude Question:** Listen to the candidate's full solution and explanation. When they are finished, you MUST call the `evaluate_solution` tool, passing their transcribed solution to it. Then, deliver the report generated by the tool as your final feedback for that question.
5. **Cycle:** After giving feedback, you can move to the next technical question by calling `prepare_technical_question` again.
Do not end the interview. Continue this cycle until the user decides to end the conversation.
"""

class InterviewAgent(Agent):
    def __init__(self, **kwargs):  # ✅ REMOVER room do construtor
        super().__init__(instructions=SYSTEM_PROMPT_INTERVIEWER, **kwargs)
        self.room = None  # ✅ Será injetado pelo framework
        self.current_question = None
        self.current_report = None
        self.on("data_received", self._on_data_received)
        logger.info("InterviewAgent inicializado e ouvindo eventos.")
    
    async def on_start(self, room: Room):
        """Método chamado automaticamente pelo framework"""
        self.room = room
        logger.info(f"✅ Agent conectado à sala: {room.name}")

    @function_tool 
    async def prepare_technical_question(self) -> str:
        logger.info("Tool 'prepare_technical_question' called.")
        try:
            with open("data/questions.json", "r", encoding="utf-8") as f:
                questions = json.load(f)
            selected_question = random.choice(questions)
            self.current_question = selected_question

            report = await generate_analysis_report(selected_question)
            self.current_report = report

            # ✅ Verificar se room está disponível
            if self.room and self.room.local_participant:
                frontend_payload = {"type": "SHOW_TECHNICAL_QUESTION", "payload": selected_question}
                await self.room.local_participant.publish_data(
                    json.dumps(frontend_payload), 
                    topic="interview_events"
                )

            return report
        except Exception as e:
            logger.error(f"Error in prepare_technical_question: {e}")
            return "Error: Could not prepare the technical question."

    @function_tool
    async def evaluate_solution(self, user_solution: str) -> str:
        logger.info("Tool 'evaluate_solution' called.")
        if not self.current_report:
            return "Error: A technical question's analysis report must be prepared first."
        try:
            prompt = SOLUTION_FEEDBACK_PROMPT.format(
                analysis_report=self.current_report,
                user_solution=user_solution
            )
            response = await MODEL.generate_content_async(prompt)
            return response.text
        except Exception as e:
            logger.error(f"Error in evaluate_solution: {e}")
            return "Error: Could not generate the feedback report."
            
    async def _on_data_received(self, dp: DataPacket):
        if dp.topic != "agent_control":
            return
            
        try:
            message = json.loads(dp.data)
            
            if message.get("type") == "SPEAK_EVALUATION_RESULT":
                code = message["payload"]["text"]
                
                feedback_text = await self.evaluate_solution(code)

                if feedback_text and self.room and self.room.local_participant:
                    logger.info("Sending and speaking feedback.")

                    # Enviar para frontend
                    frontend_payload = {
                        "type": "SHOW_EVALUATION_FEEDBACK",
                        "payload": {"text": feedback_text}
                    }
                    await self.room.local_participant.publish_data(
                        json.dumps(frontend_payload),
                        topic="interview_events" 
                    )

                    # Falar o feedback (com verificação de tamanho)
                    if len(feedback_text) > 4000:
                        feedback_text = feedback_text[:4000] + "... (truncated)"
                    await self.say(feedback_text)

        except Exception as e:
            logger.error(f"Error in _on_data_received: {e}")